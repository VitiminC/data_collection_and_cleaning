{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08c9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pathlib\n",
    "#!pip install praw==7.5.0\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from profanity_filter import ProfanityFilter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549a3851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit name ex(cats)cats\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "done\n",
      "0 out of 5\n",
      "1 out of 5\n",
      "2 out of 5\n",
      "3 out of 5\n",
      "4 out of 5\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "subreddit = input('subreddit name ex(cats)')\n",
    "time = 'all'\n",
    "#filepath = Path(f\"data/raw_data/{subreddit}.csv\"\n",
    "filepath = Path(f\"data/raw_data/{subreddit}.csv\")  #Location of output CSV\n",
    "num_posts = 5 #number of posts parsed from \"hot\" catagory *note: some will be filtered out, expect about 20% returns*\n",
    "num_comments = 10 #min number of comments per post\n",
    "get_comments = 3 #number of comments you want to download\n",
    "\n",
    "client_id = \"RBC5PY5SqCs6PfBrGx6-wg\" #\"Script\" Public id from https://www.reddit.com/prefs/apps\n",
    "client_secret = \"Emg7uUxiKPSM-lTN822UyGhgY2Ptfg\" #\"Script\" Private id from https://www.reddit.com/prefs/apps\n",
    "username = \"DataCollector123\" #reddit account username\n",
    "password = \"NotaRobot\" #reddit account password\n",
    "user_agent = \"prawdatacollector\"\n",
    "\n",
    "reddit = praw.Reddit(client_id = client_id,\n",
    "                     client_secret = client_secret,\n",
    "                     username = username,\n",
    "                     password = password,\n",
    "                     user_agent = user_agent)\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit) \n",
    "#subreddit_posts = subreddit.hot(limit=num_posts)\n",
    "subreddit_posts = subreddit.top(time_filter=time, limit=num_posts)\n",
    "\n",
    "data = []\n",
    "post_num = 1\n",
    "for post in subreddit_posts:\n",
    "    temp = []\n",
    "    try:\n",
    "        comments = post.comments.list()\n",
    "    except:\n",
    "        continue\n",
    "    if len(comments) >= num_comments and post.domain == 'i.redd.it':\n",
    "        print(post_num)\n",
    "        post_num+=1\n",
    "        temp.append(post.title)\n",
    "        temp.append(post.url)\n",
    "        temp.append(subreddit)\n",
    "        #print(post.title)\n",
    "        j = 0\n",
    "        while j != get_comments:\n",
    "            #print(comments[j].body)\n",
    "            try:\n",
    "                temp.append(post.comments[j].body)\n",
    "                j += 1\n",
    "            except:\n",
    "                temp.append(\"fill\")\n",
    "                j += 1\n",
    "        data.append(temp)\n",
    "    else:\n",
    "        post_num += 1\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "result = df.iloc[0:, :]\n",
    "for i in range(0,len(result.columns)+1):\n",
    "    if i == 0:\n",
    "        result.rename(columns={i: 'title'}, inplace=True)\n",
    "    if i == 1:\n",
    "        result.rename(columns={i: 'image_link'}, inplace=True)\n",
    "    if i == 2:\n",
    "        result.rename(columns={i: 'subreddit'}, inplace=True)\n",
    "    else:\n",
    "        result.rename(columns={i: f'comment{i-1}'}, inplace=True)\n",
    "\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "result.to_csv(filepath)  \n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "class Cleaner:\n",
    "    def __init__(self):\n",
    "        self.delete_list = ['[deleted]','[removed]','removed','deleted','https', 'Repost','repost','!gif','&#x20B','[OC]','*',\n",
    "                            'instagram','facebook','twitter','google', '/r', '/u', 'http', 'www', '/s', '#']\n",
    "        self.sub_list = [r'r/\\S+',r'\\([^)]*\\)',r'http\\S+',r'[()]',r'[:]',r'[\\([{})\\]]']\n",
    "        self.pf = ProfanityFilter()\n",
    "        self.cols = ['title', 'image_link', 'subreddit']\n",
    "    \n",
    "    #Removes emoticons\n",
    "    def remove_emojis(data):\n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                          \"]+\", re.UNICODE)\n",
    "        return re.sub(emoj, '', data)\n",
    "\n",
    "    #removes characters that appear more than twice ex: booo -> boo\n",
    "    def remove_dupes(s):\n",
    "        keep_list = ['s','e','t','f','l','m','o','p','d','n','g','r','b']\n",
    "        ans = \"\"\n",
    "        seen = ''\n",
    "        i = 0\n",
    "        while i != (len(s)-1):\n",
    "            if s[i] in keep_list and s[i] != seen:\n",
    "                if s[i] == s[i+1]:\n",
    "                    seen = s[i]\n",
    "                    ans+= s[i]\n",
    "                    ans+= s[i+1]\n",
    "            if s[i] != seen and s[i+1] != s[i]:\n",
    "                seen = s[i]\n",
    "                ans += s[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        ans += s[len(s)-1]\n",
    "        if ans[-1] == ans[-2] and ans[-1] == ans[-2]:\n",
    "            ans = ans[0:-1]\n",
    "        return ans\n",
    "\n",
    "    def splitter(text, span):\n",
    "        s = span\n",
    "        words = re.sub(r'[^\\w\\s]', '', text).split(' ')\n",
    "        t = [\" \".join(words[i:i+s]) for i in range(0, len(words), s)]\n",
    "        return t\n",
    "    \n",
    "    #Subsets dataset and define filters\n",
    "    def clean(self, data, subreddit):\n",
    "        data_subset = data.drop(self.cols, axis=1)\n",
    "        data_first = data[self.cols]\n",
    "        for i in range(len(data_subset)):\n",
    "        #for i in range(1,4):\n",
    "            for j in range(len(data_subset.iloc[i])):\n",
    "                text = data_subset.iloc[i][j]\n",
    "                try:\n",
    "                    text = remove_emojis(text)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "\n",
    "                text = remove_dupes(text)\n",
    "                print('dupe')\n",
    "\n",
    "                text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"_x000D_\", \" \").strip()\n",
    "                try:\n",
    "                    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "                    for sub in self.sub_list:\n",
    "                        text = re.sub(sub,'',text)\n",
    "                except:\n",
    "                    continue\n",
    "                #text = self.pf.censor(text)\n",
    "                if any(word in data_subset.iloc[i][j].lower() for word in self.delete_list):\n",
    "                    text = 0\n",
    "                data_subset['comment' + str(j+1)][i] = text\n",
    "            print(i,\"out of\",len(data_subset))\n",
    "    \n",
    "\n",
    "        #format data\n",
    "        result = pd.concat([data_first, data_subset], axis=1, join='inner')\n",
    "        result = result.iloc[1:, :]\n",
    "        df = pd.DataFrame(columns = ['SubmissionID', 'SubmissionTitle', 'CommentID', 'Comment', 'subreddit', 'Images'])\n",
    "        for i in range(len(result)):\n",
    "            commentid = 1\n",
    "            title = result.iloc[i][0]\n",
    "            sub = result.iloc[i][2]\n",
    "            #sub = subreddit\n",
    "            image = result.iloc[i][1]\n",
    "            for j in result.iloc[i][4:]:\n",
    "                if j == 'fill':\n",
    "                    continue\n",
    "                elif j != 0 and len(j) > 0:\n",
    "                    insert = ['placeholderID', title, commentid, j, sub, image]\n",
    "                    df = df.append(pd.DataFrame([insert],\n",
    "                          columns = ['SubmissionID', 'SubmissionTitle', 'CommentID', 'Comment', 'subreddit', 'Images']))\n",
    "                    commentid += 1\n",
    "        return df\n",
    "\n",
    "obj = Cleaner()\n",
    "data = result\n",
    "res = obj.clean(data, subreddit)\n",
    "res.to_csv(f'data/cleaned_data/{subreddit}.csv', index=False, encoding='utf8')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fecb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3d130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
